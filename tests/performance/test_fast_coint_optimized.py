"""–¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ fast_coint –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ k=2."""

import time
import numpy as np
import pandas as pd
from statsmodels.tsa.stattools import coint

from coint2.core.fast_coint import fast_coint


def generate_test_data(n_pairs=100, n_obs=500, seed=42):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏."""
    np.random.seed(seed)
    pairs = []
    
    for i in range(n_pairs):
        x = np.random.normal(0, 1, n_obs).cumsum()
        y = np.random.normal(0, 1, n_obs).cumsum()
        
        # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–∞—Ä—ã –¥–µ–ª–∞–µ–º –∫–æ–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏
        if i % 3 == 0:
            beta = np.random.uniform(0.5, 2.0)
            noise = np.random.normal(0, 0.1, n_obs)
            y = beta * x + noise
        
        pairs.append((
            pd.Series(x, name=f'X_{i}'),
            pd.Series(y, name=f'Y_{i}')
        ))
    
    return pairs


def benchmark_optimized_fast_coint(pairs, warmup=True):
    """–ë–µ–Ω—á–º–∞—Ä–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ fast_coint."""
    if warmup:
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–º–ø–∏–ª—è—Ü–∏—è
        _ = fast_coint(np.array([1.0, 2.0, 3.0]), np.array([4.0, 5.0, 6.0]))
    
    start_time = time.time()
    results = []
    
    for x, y in pairs:
        try:
            tau, pvalue, k = fast_coint(x, y, trend='n')
            results.append((tau, pvalue, k))
        except Exception as e:
            results.append((np.nan, np.nan, 0))
    
    end_time = time.time()
    return results, end_time - start_time


def benchmark_statsmodels_reference(pairs):
    """–≠—Ç–∞–ª–æ–Ω–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ statsmodels."""
    start_time = time.time()
    results = []
    
    for x, y in pairs:
        try:
            tau, pvalue, _ = coint(x, y, trend='n')
            results.append((tau, pvalue))
        except Exception:
            results.append((np.nan, np.nan))
    
    end_time = time.time()
    return results, end_time - start_time


def compare_accuracy_detailed(results_stats, results_fast):
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏."""
    tau_diffs = []
    pval_diffs = []
    lag_info = []
    
    for i, ((tau_s, pval_s), (tau_f, pval_f, k_f)) in enumerate(zip(results_stats, results_fast)):
        if not (np.isnan(tau_s) or np.isnan(tau_f)):
            tau_diff = abs(tau_s - tau_f)
            tau_diffs.append(tau_diff)
            
        if not (np.isnan(pval_s) or np.isnan(pval_f)):
            pval_diff = abs(pval_s - pval_f)
            pval_diffs.append(pval_diff)
            
        lag_info.append(k_f)
    
    return {
        'tau_diffs': tau_diffs,
        'pval_diffs': pval_diffs,
        'avg_lag': np.mean([k for k in lag_info if k > 0]),
        'lag_distribution': np.bincount(lag_info)
    }


def test_optimized_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏."""
    print("üöÄ –¢–ï–°–¢ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ô FAST_COINT")
    print("=" * 55)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ—Å—Ç–∞
    n_pairs = 100  # –ë–æ–ª—å—à–µ –ø–∞—Ä –¥–ª—è –ª—É—á—à–µ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    n_obs = 400
    n_runs = 3  # –ù–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–≥–æ–Ω–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {n_pairs} –ø–∞—Ä √ó {n_obs} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
    print(f"üîÑ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤: {n_runs}")
    print()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    pairs = generate_test_data(n_pairs, n_obs)
    
    # === STATSMODELS BASELINE ===
    print("‚è±Ô∏è  –ò–∑–º–µ—Ä—è–µ–º statsmodels.coint...")
    stats_times = []
    for run in range(n_runs):
        results_stats, time_stats = benchmark_statsmodels_reference(pairs)
        stats_times.append(time_stats)
        print(f"   –ü—Ä–æ–≥–æ–Ω {run+1}: {time_stats:.3f} —Å–µ–∫")
    
    avg_stats_time = np.mean(stats_times)
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_stats_time:.3f} —Å–µ–∫\n")
    
    # === OPTIMIZED FAST_COINT ===
    print("‚è±Ô∏è  –ò–∑–º–µ—Ä—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é fast_coint...")
    fast_times = []
    for run in range(n_runs):
        results_fast, time_fast = benchmark_optimized_fast_coint(pairs, warmup=(run==0))
        fast_times.append(time_fast)
        print(f"   –ü—Ä–æ–≥–æ–Ω {run+1}: {time_fast:.3f} —Å–µ–∫")
    
    avg_fast_time = np.mean(fast_times)
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_fast_time:.3f} —Å–µ–∫\n")
    
    # === –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
    speedup = avg_stats_time / avg_fast_time
    accuracy = compare_accuracy_detailed(results_stats, results_fast)
    
    print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    print("-" * 40)
    print(f"statsmodels —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:    {avg_stats_time:.3f} —Å–µ–∫")
    print(f"fast_coint —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:     {avg_fast_time:.3f} —Å–µ–∫")
    print(f"–£—Å–∫–æ—Ä–µ–Ω–∏–µ:                    {speedup:.1f}x")
    print()
    print("üéØ –ö–ê–ß–ï–°–¢–í–û –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞—Ä:               {len(pairs)}")
    print(f"–°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–æ—Å—Ç—å tau:         {np.mean(accuracy['tau_diffs']):.6f}")
    print(f"–°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–æ—Å—Ç—å p-value:     {np.mean(accuracy['pval_diffs']):.6f}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å tau:    {np.max(accuracy['tau_diffs']):.6f}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å p-val:  {np.max(accuracy['pval_diffs']):.6f}")
    print(f"–°—Ä–µ–¥–Ω–∏–π –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ª–∞–≥:        {accuracy['avg_lag']:.1f}")
    print()
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–∞–≥–æ–≤
    print("üìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –í–´–ë–†–ê–ù–ù–´–• –õ–ê–ì–û–í:")
    lag_dist = accuracy['lag_distribution']
    for k, count in enumerate(lag_dist):
        if count > 0:
            print(f"   k={k}: {count} –ø–∞—Ä ({count/len(pairs)*100:.1f}%)")
    print()
    
    # === –ü–†–û–í–ï–†–ö–ò ===
    expected_speedup = 4.0  # –û–∂–∏–¥–∞–µ–º —É—Å–∫–æ—Ä–µ–Ω–∏–µ –º–∏–Ω–∏–º—É–º –≤ 4x
    max_pval_diff = 0.05   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å p-value
    
    print("‚úÖ –ü–†–û–í–ï–†–ö–ò:")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è
    if speedup >= expected_speedup:
        print(f"‚úÖ –£—Å–∫–æ—Ä–µ–Ω–∏–µ {speedup:.1f}x >= {expected_speedup}x ‚Äî –û–¢–õ–ò–ß–ù–û!")
    else:
        print(f"‚ö†Ô∏è  –£—Å–∫–æ—Ä–µ–Ω–∏–µ {speedup:.1f}x < {expected_speedup}x ‚Äî –ø—Ä–∏–µ–º–ª–µ–º–æ, –Ω–æ –º–æ–∂–Ω–æ –ª—É—á—à–µ")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
    avg_pval_diff = np.mean(accuracy['pval_diffs'])
    if avg_pval_diff <= max_pval_diff:
        print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å p-value ({avg_pval_diff:.4f}) ‚Äî –û–¢–õ–ò–ß–ù–û!")
    else:
        print(f"‚ö†Ô∏è  –¢–æ—á–Ω–æ—Å—Ç—å p-value ({avg_pval_diff:.4f}) ‚Äî —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ª–∞–≥–∏ –≤—ã–±–∏—Ä–∞—é—Ç—Å—è –ø–æ AIC, –∞ –Ω–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ k=2
    if accuracy['avg_lag'] != 2.0 or len(lag_dist) > 3:
        print(f"‚úÖ AIC-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –≤—ã–±–∏—Ä–∞—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ –ª–∞–≥–∏!")
    else:
        print(f"‚ö†Ô∏è  –í–æ–∑–º–æ–∂–Ω–æ, –ª–∞–≥–∏ –≤—ã–±–∏—Ä–∞—é—Ç—Å—è –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ")
    
    print(f"\nüéâ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(f"üí° –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ {n_pairs} –ø–∞—Ä: {(avg_stats_time - avg_fast_time):.2f} —Å–µ–∫")
    print(f"üìà –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.1f}x")
    
    return {
        'speedup': speedup,
        'accuracy': accuracy,
        'stats_time': avg_stats_time,
        'fast_time': avg_fast_time
    }


if __name__ == "__main__":
    test_optimized_performance() 