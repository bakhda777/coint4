"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∑–∞–≥—Ä—É–∑–∫—É –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è walk-forward –∞–Ω–∞–ª–∏–∑–∞.
"""

import pandas as pd
import numpy as np
from typing import Dict, Tuple, Optional, Any
from pathlib import Path
import logging
from dataclasses import dataclass

from coint2.core.data_prep import prepare_walk_forward_slices, validate_no_lookahead
from ..lookahead_validator import LookaheadValidator

logger = logging.getLogger(__name__)


@dataclass
class WalkForwardData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è walk-forward —à–∞–≥–∞."""
    full_data: pd.DataFrame
    training_data: pd.DataFrame
    testing_data: pd.DataFrame
    training_start: pd.Timestamp
    training_end: pd.Timestamp
    testing_start: pd.Timestamp
    testing_end: pd.Timestamp
    step_index: int


class OptimizationDataManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
    –ò–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç –≤—Å—é –ª–æ–≥–∏–∫—É –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –∏ walk-forward
        """
        self.config = config
        self.data_dir = config.get('data_dir', 'data_downloaded')
        self.walk_forward_config = config.get('walk_forward', {})
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä lookahead bias
        self.lookahead_validator = LookaheadValidator(strict_mode=True)
        
        # –ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._data_cache = {}
        
    def load_walk_forward_data(
        self, 
        training_start: pd.Timestamp,
        training_end: pd.Timestamp,
        testing_start: pd.Timestamp,
        testing_end: pd.Timestamp,
        step_index: int = 0
    ) -> WalkForwardData:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ walk-forward —à–∞–≥–∞.
        
        Args:
            training_start: –ù–∞—á–∞–ª–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            training_end: –ö–æ–Ω–µ—Ü —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            testing_start: –ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            testing_end: –ö–æ–Ω–µ—Ü —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            step_index: –ò–Ω–¥–µ–∫—Å walk-forward —à–∞–≥–∞
            
        Returns:
            WalkForwardData —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            
        Raises:
            ValueError: –ü—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ lookahead bias
        """
        logger.info(f"üìà –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è walk-forward —à–∞–≥–∞ {step_index}")
        logger.info(f"   –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {training_start.date()} -> {training_end.date()}")
        logger.info(f"   –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {testing_start.date()} -> {testing_end.date()}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞
        cache_key = f"{training_start}_{training_end}_{testing_start}_{testing_end}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if cache_key in self._data_cache:
            logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫—ç—à–µ")
            return self._data_cache[cache_key]
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            training_slice, testing_slice, step_df, stats = prepare_walk_forward_slices(
                training_start=training_start,
                training_end=training_end,
                testing_start=testing_start,
                testing_end=testing_end,
                config=self.config,
                data_dir=self.data_dir
            )
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ lookahead bias (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—É—Å—Ç—ã–µ)
            if not training_slice.empty and not testing_slice.empty:
                self._validate_data_split(training_slice, testing_slice)
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            walk_forward_data = WalkForwardData(
                full_data=step_df,
                training_data=training_slice,
                testing_data=testing_slice,
                training_start=training_start,
                training_end=training_end,
                testing_start=testing_start,
                testing_end=testing_end,
                step_index=step_index
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self._data_cache[cache_key] = walk_forward_data
            
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ë–ï–ó lookahead bias:")
            logger.info(f"   –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Å—Ä–µ–∑: {training_slice.shape}")
            logger.info(f"   –¢–µ—Å—Ç–æ–≤—ã–π —Å—Ä–µ–∑: {testing_slice.shape}")
            logger.info(f"   –ú–µ—Ç–æ–¥ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {stats.get('normalization_method')}")
            logger.info(f"   –°–∏–º–≤–æ–ª–æ–≤ —É–¥–∞–ª–µ–Ω–æ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {stats.get('symbols_removed', 0)}")
            
            return walk_forward_data
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def _validate_data_split(
        self, 
        training_data: pd.DataFrame,
        testing_data: pd.DataFrame
    ) -> None:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/test.
        
        Args:
            training_data: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            testing_data: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Raises:
            ValueError: –ü—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ lookahead bias –∏–ª–∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–±–ª–µ–º
        """
        if training_data.empty or testing_data.empty:
            raise ValueError("–û–¥–∏–Ω –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –ø—É—Å—Ç")
        
        train_end = training_data.index.max()
        test_start = testing_data.index.min()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        if train_end >= test_start:
            raise ValueError(
                f"–ö–†–ò–¢–ò–ß–ù–û: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö! "
                f"Train –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è {train_end}, Test –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è {test_start}"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ gap
        gap = test_start - train_end
        gap_minutes = self.walk_forward_config.get('gap_minutes', 15)
        min_gap = pd.Timedelta(minutes=gap_minutes)
        
        if gap < min_gap:
            raise ValueError(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π gap –º–µ–∂–¥—É train –∏ test: {gap} < {min_gap}"
            )
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ lookahead_validator
        gap_days = gap_minutes / (24 * 60)
        is_valid, message = self.lookahead_validator.validate_data_split(
            training_data, testing_data, gap_days
        )
        
        if not is_valid:
            raise ValueError(f"Lookahead validator: {message}")
    
    def get_walk_forward_periods(self) -> list:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è walk-forward –∞–Ω–∞–ª–∏–∑–∞.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (training_start, training_end, testing_start, testing_end)
        """
        start_date = pd.to_datetime(self.walk_forward_config['start_date'])
        end_date = pd.to_datetime(self.walk_forward_config['end_date'])
        training_days = self.walk_forward_config['training_period_days']
        testing_days = self.walk_forward_config['testing_period_days']
        step_days = self.walk_forward_config['step_size_days']
        gap_minutes = self.walk_forward_config.get('gap_minutes', 15)
        
        periods = []
        current_start = start_date
        
        while current_start + pd.Timedelta(days=training_days + testing_days) <= end_date:
            training_start = current_start
            training_end = training_start + pd.Timedelta(days=training_days)
            testing_start = training_end + pd.Timedelta(minutes=gap_minutes)
            testing_end = testing_start + pd.Timedelta(days=testing_days)
            
            periods.append((training_start, training_end, testing_start, testing_end))
            
            current_start += pd.Timedelta(days=step_days)
        
        return periods
    
    def clear_cache(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à –¥–∞–Ω–Ω—ã—Ö."""
        self._data_cache.clear()
        logger.info("üóëÔ∏è –ö—ç—à –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω")
    
    def get_cache_size(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞."""
        return len(self._data_cache)
