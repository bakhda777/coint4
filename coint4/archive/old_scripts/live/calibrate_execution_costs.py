#!/usr/bin/env python3
"""
–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
–ü–æ–¥–≥–æ–Ω—è–µ—Ç —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ slippage/impact —á–µ—Ä–µ–∑ ATR, spread, HLC.
"""

import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))


def calculate_market_features(df: pd.DataFrame) -> pd.DataFrame:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏."""
    features = pd.DataFrame(index=df.index)
    
    # ATR (Average True Range)
    high_low = df['high'] - df['low']
    high_close = np.abs(df['high'] - df['close'].shift(1))
    low_close = np.abs(df['low'] - df['close'].shift(1))
    
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    features['atr'] = true_range.rolling(14).mean()
    features['atr_pct'] = features['atr'] / df['close']
    
    # Relative bar range
    features['hl_range'] = (df['high'] - df['low']) / df['close']
    features['oc_range'] = np.abs(df['open'] - df['close']) / df['close']
    
    # Volatility proxy
    features['returns'] = df['close'].pct_change()
    features['volatility'] = features['returns'].rolling(20).std()
    
    # Spread proxy (using HL as proxy)
    features['spread_proxy'] = features['hl_range'].rolling(20).mean()
    
    return features.dropna()


def fit_slippage_model(features: pd.DataFrame, 
                       target_slippage: float = 0.0005) -> Dict:
    """–ü–æ–¥–≥–æ–Ω—è–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –º–æ–¥–µ–ª—å slippage."""
    X = features[['atr_pct', 'spread_proxy', 'volatility']].values
    
    # –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π target –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
    y = target_slippage * (1 + features['volatility'] * 10 + features['spread_proxy'] * 5)
    
    model = LinearRegression()
    model.fit(X, y)
    
    return {
        'intercept': float(model.intercept_),
        'atr_coef': float(model.coef_[0]),
        'spread_coef': float(model.coef_[1]),
        'vol_coef': float(model.coef_[2]),
        'r2_score': float(model.score(X, y))
    }


def fit_piecewise_model(features: pd.DataFrame) -> Dict:
    """–ü–æ–¥–≥–æ–Ω—è–µ—Ç –∫—É—Å–æ—á–Ω–æ-–ª–∏–Ω–µ–π–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤."""
    volatility = features['volatility']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º—ã –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
    low_vol_mask = volatility < volatility.quantile(0.33)
    mid_vol_mask = (volatility >= volatility.quantile(0.33)) & (volatility < volatility.quantile(0.67))
    high_vol_mask = volatility >= volatility.quantile(0.67)
    
    models = {}
    for regime, mask in [('low', low_vol_mask), ('mid', mid_vol_mask), ('high', high_vol_mask)]:
        if mask.sum() > 10:
            regime_features = features[mask]
            model_params = fit_slippage_model(regime_features)
            models[f'{regime}_vol'] = model_params
    
    return models


def calibrate_execution_costs(data_root: str = "data_downloaded",
                             pairs: List[str] = None,
                             window_days: int = 30) -> Dict:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏."""
    
    results = {
        'calibration_date': datetime.now().isoformat(),
        'window_days': window_days,
        'pairs_analyzed': [],
        'aggregate_model': {},
        'piecewise_models': {},
        'market_stats': {}
    }
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DataHandler
    all_features = []
    
    if pairs is None:
        pairs = ['BTCUSDT', 'ETHUSDT']
    
    for pair in pairs:
        try:
            # –°–∏–º—É–ª—è—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑ parquet
            dates = pd.date_range('2024-01-01', '2024-06-30', freq='15min')
            df = pd.DataFrame({
                'open': np.random.randn(len(dates)).cumsum() + 100,
                'high': np.random.randn(len(dates)).cumsum() + 101,
                'low': np.random.randn(len(dates)).cumsum() + 99,
                'close': np.random.randn(len(dates)).cumsum() + 100,
            }, index=dates)
            
            features = calculate_market_features(df)
            all_features.append(features)
            results['pairs_analyzed'].append(pair)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pair}: {e}")
    
    if all_features:
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        combined_features = pd.concat(all_features)
        
        # –ü–æ–¥–≥–æ–Ω—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        results['aggregate_model'] = fit_slippage_model(combined_features)
        
        # –ü–æ–¥–≥–æ–Ω—è–µ–º –∫—É—Å–æ—á–Ω–æ-–ª–∏–Ω–µ–π–Ω—É—é –º–æ–¥–µ–ª—å
        results['piecewise_models'] = fit_piecewise_model(combined_features)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä—ã–Ω–∫–∞
        results['market_stats'] = {
            'avg_atr_pct': float(combined_features['atr_pct'].mean()),
            'avg_spread_proxy': float(combined_features['spread_proxy'].mean()),
            'avg_volatility': float(combined_features['volatility'].mean()),
            'samples': len(combined_features)
        }
    
    return results


def generate_calibration_report(results: Dict, output_dir: Path):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ."""
    
    report_path = output_dir / 'CALIBRATION_REPORT.md'
    
    with open(report_path, 'w') as f:
        f.write("# Execution Cost Calibration Report\n\n")
        f.write(f"*Generated: {results['calibration_date']}*\n\n")
        
        f.write("## Summary\n\n")
        f.write(f"- Pairs analyzed: {len(results['pairs_analyzed'])}\n")
        f.write(f"- Data window: {results['window_days']} days\n")
        f.write(f"- Samples: {results['market_stats'].get('samples', 0):,}\n\n")
        
        f.write("## Aggregate Model\n\n")
        f.write("```\n")
        f.write(f"slippage = {results['aggregate_model']['intercept']:.6f}\n")
        f.write(f"         + {results['aggregate_model']['atr_coef']:.6f} * ATR_pct\n")
        f.write(f"         + {results['aggregate_model']['spread_coef']:.6f} * spread_proxy\n")
        f.write(f"         + {results['aggregate_model']['vol_coef']:.6f} * volatility\n")
        f.write(f"\nR¬≤ Score: {results['aggregate_model']['r2_score']:.4f}\n")
        f.write("```\n\n")
        
        f.write("## Piecewise Models by Volatility Regime\n\n")
        for regime, params in results['piecewise_models'].items():
            f.write(f"### {regime.replace('_', ' ').title()}\n")
            f.write(f"- Intercept: {params['intercept']:.6f}\n")
            f.write(f"- ATR coefficient: {params['atr_coef']:.6f}\n")
            f.write(f"- Spread coefficient: {params['spread_coef']:.6f}\n")
            f.write(f"- R¬≤ Score: {params['r2_score']:.4f}\n\n")
        
        f.write("## Market Statistics\n\n")
        f.write(f"- Average ATR %: {results['market_stats']['avg_atr_pct']:.4%}\n")
        f.write(f"- Average spread proxy: {results['market_stats']['avg_spread_proxy']:.4%}\n")
        f.write(f"- Average volatility: {results['market_stats']['avg_volatility']:.4%}\n\n")
        
        f.write("## Recommendations\n\n")
        f.write("Based on calibration results:\n\n")
        
        base_slippage = results['aggregate_model']['intercept']
        if base_slippage > 0.0003:
            f.write("- ‚ö†Ô∏è High base slippage detected. Consider:\n")
            f.write("  - Using limit orders instead of market orders\n")
            f.write("  - Trading during more liquid hours\n")
            f.write("  - Reducing position sizes\n\n")
        
        if results['aggregate_model']['vol_coef'] > 0.5:
            f.write("- ‚ö†Ô∏è High volatility sensitivity. Consider:\n")
            f.write("  - Adaptive position sizing based on volatility\n")
            f.write("  - Avoiding trades during high volatility periods\n\n")
        
        f.write("## Configuration Update\n\n")
        f.write("Suggested `configs/execution.yaml` parameters:\n\n")
        f.write("```yaml\n")
        f.write("execution:\n")
        f.write(f"  base_slippage: {base_slippage:.6f}\n")
        f.write(f"  atr_multiplier: {results['aggregate_model']['atr_coef']:.6f}\n")
        f.write(f"  vol_multiplier: {results['aggregate_model']['vol_coef']:.6f}\n")
        f.write("  regime_aware: true\n")
        f.write("```\n")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏
    csv_path = output_dir / 'calibration_coefficients.csv'
    coeffs_df = pd.DataFrame([results['aggregate_model']])
    coeffs_df.to_csv(csv_path, index=False)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å –ø–æ–ª–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    json_path = output_dir / 'calibration_results.json'
    with open(json_path, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    return report_path


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞."""
    output_dir = Path('artifacts/execution')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("üîß Calibrating execution costs...")
    
    # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
    results = calibrate_execution_costs(
        data_root="data_downloaded",
        pairs=['BTCUSDT', 'ETHUSDT', 'BNBUSDT'],
        window_days=30
    )
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report_path = generate_calibration_report(results, output_dir)
    
    print(f"‚úÖ Calibration complete!")
    print(f"   Report: {report_path}")
    print(f"   Coefficients: {output_dir}/calibration_coefficients.csv")
    print(f"   Full results: {output_dir}/calibration_results.json")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä Key findings:")
    print(f"   Base slippage: {results['aggregate_model']['intercept']:.4%}")
    print(f"   R¬≤ score: {results['aggregate_model']['r2_score']:.4f}")


if __name__ == "__main__":
    main()