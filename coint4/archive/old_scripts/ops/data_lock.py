#!/usr/bin/env python3
"""
Data Lock - –∑–∞–º–æ—Ä–æ–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.
–°–∫–∞–Ω–∏—Ä—É–µ—Ç DATA_ROOT –∏ —Å–æ–∑–¥–∞—ë—Ç –º–∞–Ω–∏—Ñ–µ—Å—Ç —Å sha256, –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.
"""

import sys
import argparse
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import pandas as pd


class DataLockManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–º–æ—Ä–æ–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞."""
    
    def __init__(self, data_root: str = "data_downloaded", verbose: bool = False):
        """Initialize data lock manager."""
        self.data_root = Path(data_root)
        self.verbose = verbose
        self.lock_data = {
            "generated_at": datetime.now().isoformat(),
            "data_root": str(self.data_root),
            "files": [],
            "summary": {
                "total_files": 0,
                "total_size_bytes": 0,
                "total_rows": 0,
                "time_range": {"min": None, "max": None},
                "symbols": set(),
                "timeframes": set()
            }
        }
    
    def _calculate_sha256(self, file_path: Path) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ñ–∞–π–ª–∞."""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def _analyze_parquet_file(self, file_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ parquet —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
        try:
            df = pd.read_parquet(file_path)
            
            file_info = {
                "path": str(file_path),
                "size_bytes": file_path.stat().st_size,
                "sha256": self._calculate_sha256(file_path),
                "rows": len(df),
                "columns": list(df.columns),
                "time_range": {"min": None, "max": None},
                "symbols": [],
                "timeframe": None
            }
            
            # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
            if 'timestamp' in df.columns:
                if not df['timestamp'].empty:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, timestamp –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ —É–∂–µ datetime
                    if df['timestamp'].dtype == 'int64':
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥ –≤ datetime
                        min_time = pd.to_datetime(df['timestamp'].min(), unit='ms')
                        max_time = pd.to_datetime(df['timestamp'].max(), unit='ms')
                    else:
                        min_time = pd.to_datetime(df['timestamp'].min())
                        max_time = pd.to_datetime(df['timestamp'].max())
                    
                    file_info["time_range"]["min"] = str(min_time)
                    file_info["time_range"]["max"] = str(max_time)
                    
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    if (self.lock_data["summary"]["time_range"]["min"] is None or 
                        min_time < pd.to_datetime(self.lock_data["summary"]["time_range"]["min"])):
                        self.lock_data["summary"]["time_range"]["min"] = str(min_time)
                        
                    if (self.lock_data["summary"]["time_range"]["max"] is None or 
                        max_time > pd.to_datetime(self.lock_data["summary"]["time_range"]["max"])):
                        self.lock_data["summary"]["time_range"]["max"] = str(max_time)
            
            # –ê–Ω–∞–ª–∏–∑ —Å–∏–º–≤–æ–ª–æ–≤
            if 'symbol' in df.columns:
                unique_symbols = df['symbol'].unique().tolist()
                file_info["symbols"] = unique_symbols
                self.lock_data["summary"]["symbols"].update(unique_symbols)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –¥–∞–Ω–Ω—ã—Ö
            if 'timestamp' in df.columns and len(df) > 1:
                if df['timestamp'].dtype == 'int64':
                    # Timestamps –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
                    time_diff = (df['timestamp'].iloc[1] - df['timestamp'].iloc[0]) / 1000 / 60  # –≤ –º–∏–Ω—É—Ç–∞—Ö
                    minutes = int(time_diff)
                else:
                    time_diff = pd.to_datetime(df['timestamp'].iloc[1]) - pd.to_datetime(df['timestamp'].iloc[0])
                    minutes = int(time_diff.total_seconds() / 60)
                
                if minutes == 1:
                    file_info["timeframe"] = "1m"
                elif minutes == 5:
                    file_info["timeframe"] = "5m"
                elif minutes == 15:
                    file_info["timeframe"] = "15m"
                elif minutes == 60:
                    file_info["timeframe"] = "1h"
                elif minutes == 240:
                    file_info["timeframe"] = "4h"
                elif minutes == 1440:
                    file_info["timeframe"] = "1d"
                else:
                    file_info["timeframe"] = f"{minutes}m"
                
                if file_info["timeframe"]:
                    self.lock_data["summary"]["timeframes"].add(file_info["timeframe"])
            
            return file_info
            
        except Exception as e:
            if self.verbose:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path}: {e}")
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            return {
                "path": str(file_path),
                "size_bytes": file_path.stat().st_size,
                "sha256": self._calculate_sha256(file_path),
                "rows": 0,
                "columns": [],
                "time_range": {"min": None, "max": None},
                "symbols": [],
                "timeframe": None,
                "error": str(e)
            }
    
    def scan_data_directory(self) -> None:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –¥–∞–Ω–Ω—ã–º–∏."""
        if not self.data_root.exists():
            raise FileNotFoundError(f"Data directory not found: {self.data_root}")
        
        if self.verbose:
            print(f"üìÇ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ {self.data_root}...")
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö parquet —Ñ–∞–π–ª–æ–≤
        parquet_files = list(self.data_root.rglob("*.parquet"))
        
        if not parquet_files:
            print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ parquet —Ñ–∞–π–ª–æ–≤ –≤ {self.data_root}")
            return
        
        if self.verbose:
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(parquet_files)} parquet —Ñ–∞–π–ª–æ–≤")
        
        for i, parquet_file in enumerate(parquet_files):
            if self.verbose:
                print(f"   {i+1:3d}/{len(parquet_files)}: {parquet_file.name}")
            
            file_info = self._analyze_parquet_file(parquet_file)
            self.lock_data["files"].append(file_info)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏
            self.lock_data["summary"]["total_files"] += 1
            self.lock_data["summary"]["total_size_bytes"] += file_info["size_bytes"]
            self.lock_data["summary"]["total_rows"] += file_info["rows"]
    
    def generate_lock_files(self, output_dir: str = "artifacts/data") -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –∑–∞–º–æ—Ä–æ–∑–∫–∏."""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è sets –≤ lists –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.lock_data["summary"]["symbols"] = sorted(list(self.lock_data["summary"]["symbols"]))
        self.lock_data["summary"]["timeframes"] = sorted(list(self.lock_data["summary"]["timeframes"]))
        
        # JSON –º–∞–Ω–∏—Ñ–µ—Å—Ç
        json_file = output_path / "DATA_LOCK.json"
        with open(json_file, 'w') as f:
            json.dump(self.lock_data, f, indent=2, ensure_ascii=False)
        
        if self.verbose:
            print(f"üíæ –°–æ–∑–¥–∞–Ω {json_file}")
        
        # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á—ë—Ç
        self._generate_markdown_report(output_path / "DATA_LOCK.md")
    
    def _generate_markdown_report(self, output_file: Path) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è markdown –æ—Ç—á—ë—Ç–∞."""
        summary = self.lock_data["summary"]
        
        report = f"""# Data Lock Report
Generated: {self.lock_data['generated_at']}

## Summary
- **Data Root:** `{self.lock_data['data_root']}`
- **Total Files:** {summary['total_files']}
- **Total Size:** {summary['total_size_bytes'] / 1024 / 1024:.1f} MB
- **Total Rows:** {summary['total_rows']:,}
- **Time Range:** {summary['time_range']['min']} to {summary['time_range']['max']}

## Symbols ({len(summary['symbols'])})
{', '.join(summary['symbols'][:50])}{'...' if len(summary['symbols']) > 50 else ''}

## Timeframes
{', '.join(summary['timeframes'])}

## Files Detail
| File | Size (KB) | Rows | SHA256 (first 8) | Timeframe |
|------|-----------|------|------------------|-----------|
"""
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–∞—Ö
        for file_info in self.lock_data["files"][:20]:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 20
            size_kb = file_info["size_bytes"] / 1024
            sha256_short = file_info["sha256"][:8]
            timeframe = file_info.get("timeframe", "N/A")
            
            report += f"| `{Path(file_info['path']).name}` | {size_kb:.1f} | {file_info['rows']:,} | `{sha256_short}` | {timeframe} |\n"
        
        if len(self.lock_data["files"]) > 20:
            report += f"\n... –∏ –µ—â—ë {len(self.lock_data['files']) - 20} —Ñ–∞–π–ª–æ–≤\n"
        
        report += f"""
## Integrity Verification
To verify data integrity:
```bash
python scripts/data_lock.py --verify artifacts/data/DATA_LOCK.json
```

## Reproduction Command
```bash
python scripts/reproduce.py --data-lock artifacts/data/DATA_LOCK.json
```
"""
        
        with open(output_file, 'w') as f:
            f.write(report)
        
        if self.verbose:
            print(f"üìÑ –°–æ–∑–¥–∞–Ω {output_file}")
    
    def verify_lock(self, lock_file: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–∏–≤ lock —Ñ–∞–π–ª–∞."""
        if self.verbose:
            print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–æ—Ç–∏–≤ {lock_file}")
        
        try:
            with open(lock_file, 'r') as f:
                expected_lock = json.load(f)
            
            mismatches = []
            
            for expected_file in expected_lock["files"]:
                file_path = Path(expected_file["path"])
                
                if not file_path.exists():
                    mismatches.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {file_path}")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ SHA256
                actual_sha256 = self._calculate_sha256(file_path)
                if actual_sha256 != expected_file["sha256"]:
                    mismatches.append(f"SHA256 mismatch: {file_path}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                actual_size = file_path.stat().st_size
                if actual_size != expected_file["size_bytes"]:
                    mismatches.append(f"Size mismatch: {file_path}")
            
            if mismatches:
                print("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è:")
                for mismatch in mismatches:
                    print(f"   - {mismatch}")
                return False
            else:
                print("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç lock –º–∞–Ω–∏—Ñ–µ—Å—Ç—É")
                return True
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
            return False


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(description='Data Lock - –∑–∞–º–æ—Ä–æ–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏')
    
    parser.add_argument('--data-root', '--root', default='data_downloaded',
                       help='–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('--output-dir', default='artifacts/data',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è lock —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('--scan', action='store_true',
                       help='–†–µ–∂–∏–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏—è lock')
    parser.add_argument('--verify', metavar='LOCK_FILE',
                       help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–∏–≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ lock —Ñ–∞–π–ª–∞')
    parser.add_argument('--verbose', action='store_true',
                       help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
    
    args = parser.parse_args()
    
    manager = DataLockManager(
        data_root=args.data_root,
        verbose=args.verbose
    )
    
    if args.verify:
        success = manager.verify_lock(args.verify)
        sys.exit(0 if success else 1)
    elif args.scan or (not args.verify):
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ lock
        manager.scan_data_directory()
        manager.generate_lock_files(args.output_dir)
        
        if args.verbose:
            print(f"\n‚úÖ Data lock –∑–∞–≤–µ—Ä—à—ë–Ω:")
            print(f"   JSON: {args.output_dir}/DATA_LOCK.json")
            print(f"   MD:   {args.output_dir}/DATA_LOCK.md")


if __name__ == '__main__':
    main()