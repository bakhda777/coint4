#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø–∞—Ä.
–¢–û–ß–ù–û –ü–û–í–¢–û–†–Ø–ï–¢ –ª–æ–≥–∏–∫—É –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞ walk-forward –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã.
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import time
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(str(Path(__file__).parent.parent / "src"))

from coint2.utils.config import load_config
from coint2.core.data_loader import DataHandler, load_master_dataset
from coint2.core.normalization_improvements import preprocess_and_normalize_data
from coint2.core import math_utils
from coint2.pipeline.filters import filter_pairs_by_coint_and_half_life
from coint2.utils.logger import get_logger

def preselect_and_save_pairs():
    """
    –¢–û–ß–ù–û –ü–û–í–¢–û–†–Ø–ï–¢ –ª–æ–≥–∏–∫—É –æ—Ç–±–æ—Ä–∞ –ø–∞—Ä –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞ walk-forward –∞–Ω–∞–ª–∏–∑–∞.
    """
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø–∞—Ä...")
    print("üìä –¢–û–ß–ù–û –ü–û–í–¢–û–†–Ø–ï–ú –ª–æ–≥–∏–∫—É –ø–µ—Ä–≤–æ–≥–æ walk-forward —à–∞–≥–∞")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–æ–±—ã—á–Ω—É—é –∏–ª–∏ relaxed)
    use_relaxed = os.getenv("USE_RELAXED_CONFIG", "false").lower() == "true"
    config_path = "configs/relaxed_config.yaml" if use_relaxed else "configs/main_2024.yaml"

    print(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {config_path}")
    if use_relaxed:
        print("‚ö° RELAXED —Ä–µ–∂–∏–º: –æ—Å–ª–∞–±–ª–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")

    cfg = load_config(config_path)
    logger = get_logger("preselect_pairs")

    # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–≤—ã–π walk-forward —à–∞–≥
    start_date = pd.to_datetime(cfg.walk_forward.start_date)
    bar_minutes = getattr(cfg.pair_selection, "bar_minutes", None) or 15
    bar_delta = pd.Timedelta(minutes=bar_minutes)

    # –ü–µ—Ä–≤—ã–π —à–∞–≥ walk-forward
    current_test_start = start_date
    training_start = current_test_start - pd.Timedelta(days=cfg.walk_forward.training_period_days)
    training_end = current_test_start - bar_delta
    testing_start = current_test_start
    testing_end = testing_start + pd.Timedelta(days=cfg.walk_forward.testing_period_days)

    print(f"üóìÔ∏è  –ü–ï–†–í–´–ô WALK-FORWARD –®–ê–ì:")
    print(f"   –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {training_start.date()} -> {training_end.date()}")
    print(f"   –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {testing_start.date()} -> {testing_end.date()}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
    handler = DataHandler(cfg)
    print("üìà –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥ (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ + —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
        full_range_start = training_start
        full_range_end = testing_end

        raw_data = load_master_dataset(
            data_path=cfg.data_dir,
            start_date=full_range_start,
            end_date=full_range_end
        )
        
        if raw_data.empty:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø–∞—Ä.")
            return

        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {raw_data.shape[0]} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {len(raw_data['symbol'].unique())} —Å–∏–º–≤–æ–ª–æ–≤")

        # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ pivot table
        step_df = raw_data.pivot_table(index="timestamp", columns="symbol", values="close")
        print(f"üìä Pivot table: {step_df.shape}")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¢–û–õ–¨–ö–û —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø–∞—Ä
        training_slice = step_df.loc[training_start:training_end]
        print(f"üìä –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Å—Ä–µ–∑: {training_slice.shape}")

        if training_slice.empty or len(training_slice.columns) < 2:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return

        # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: —Å–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        training_normalization_params = {}
        if not training_slice.empty:
            for col in training_slice.columns:
                first_valid_idx = training_slice[col].first_valid_index()
                if first_valid_idx is not None:
                    training_normalization_params[col] = training_slice.loc[first_valid_idx, col]

        # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        print("üîÑ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ)...")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        norm_method = getattr(cfg.data_processing, 'normalization_method', 'minmax')
        fill_method = getattr(cfg.data_processing, 'fill_method', 'ffill')
        min_history_ratio = getattr(cfg.data_processing, 'min_history_ratio', 0.8)
        handle_constant = getattr(cfg.data_processing, 'handle_constant', True)

        print(f"  –ü—Ä–∏–º–µ–Ω—è–µ–º –º–µ—Ç–æ–¥ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {norm_method}")
        normalized_training, norm_stats = preprocess_and_normalize_data(
            training_slice,
            min_history_ratio=min_history_ratio,
            fill_method=fill_method,
            norm_method=norm_method,
            handle_constant=handle_constant
        )
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        print("  –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:")
        print(f"    –ò—Å—Ö–æ–¥–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: {norm_stats['initial_symbols']}")
        print(f"    –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è: {norm_stats['low_history_ratio']}")
        print(f"    –ü–æ—Å—Ç–æ—è–Ω–Ω–∞—è —Ü–µ–Ω–∞: {norm_stats['constant_price']}")
        print(f"    NaN –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {norm_stats['nan_after_norm']}")
        print(f"    –ò—Ç–æ–≥–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã: {norm_stats['final_symbols']} ({norm_stats['final_symbols']/norm_stats['initial_symbols']*100:.1f}%)")

        if len(normalized_training.columns) < 2:
            print("‚ùå –ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–µ–Ω–µ–µ 2 —Å–∏–º–≤–æ–ª–æ–≤")
            return

        print(f"‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ {len(normalized_training.columns)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: SSD computation
        print("üîç –†–∞—Å—á–µ—Ç SSD –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä (–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)...")
        # –°–Ω–∞—á–∞–ª–∞ —Å—á–∏—Ç–∞–µ–º SSD –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä
        ssd = math_utils.calculate_ssd(normalized_training, top_k=None)
        print(f"  SSD —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–≤—Å–µ –ø–∞—Ä—ã): {len(ssd)} –ø–∞—Ä")

        # –ó–∞—Ç–µ–º –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ top-N –ø–∞—Ä –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        ssd_top_n = cfg.pair_selection.ssd_top_n
        if len(ssd) > ssd_top_n:
            print(f"  –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ top-{ssd_top_n} –ø–∞—Ä –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            ssd = ssd.sort_values().head(ssd_top_n)

        ssd_pairs = [(s1, s2) for s1, s2 in ssd.index]
        print(f"üìà –ù–∞–π–¥–µ–Ω–æ {len(ssd_pairs)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ SSD")

        # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: Filter pairs
        print("üî¨ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–∞—Ä –ø–æ –∫–æ–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏ –¥—Ä—É–≥–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º...")

        filtered_pairs = filter_pairs_by_coint_and_half_life(
            ssd_pairs,
            training_slice,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ù–ï–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏!
            pvalue_threshold=cfg.pair_selection.coint_pvalue_threshold,
            min_beta=cfg.filter_params.min_beta,
            max_beta=cfg.filter_params.max_beta,
            min_half_life=cfg.filter_params.min_half_life_days,
            max_half_life=cfg.filter_params.max_half_life_days,
            min_mean_crossings=cfg.filter_params.min_mean_crossings,
            max_hurst_exponent=cfg.filter_params.max_hurst_exponent,
            save_filter_reasons=cfg.pair_selection.save_filter_reasons,
            kpss_pvalue_threshold=cfg.pair_selection.kpss_pvalue_threshold,
        )

        print(f"  –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: {len(ssd_pairs)} ‚Üí {len(filtered_pairs)} –ø–∞—Ä")

        if not filtered_pairs:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –ø–∞—Ä—ã –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
            return

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(filtered_pairs)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–∞—Ä")

        # –¢–û–ß–ù–û –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∞—Ä—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        quality_sorted_pairs = sorted(filtered_pairs, key=lambda x: abs(x[4]), reverse=True)  # x[4] = std
        active_pairs = quality_sorted_pairs  # –ë–µ—Ä–µ–º –í–°–ï –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã

        print("  –¢–æ–ø-3 –ø–∞—Ä—ã –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ —Å–ø—Ä–µ–¥–∞:")
        for i, (s1, s2, beta, mean, std, metrics) in enumerate(active_pairs[:3], 1):
            print(f"    {i}. {s1}-{s2}: beta={beta:.4f}, std={std:.4f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ DataFrame –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
        pairs_list = []
        for s1, s2, beta, mean, std, metrics in active_pairs:
            pairs_list.append({
                's1': s1,
                's2': s2,
                'beta': beta,
                'mean': mean,
                'std': std,
                'half_life': metrics.get('half_life', 0.0),
                'pvalue': metrics.get('pvalue', 0.05),
                'hurst': metrics.get('hurst', 0.5),
                'mean_crossings': metrics.get('mean_crossings', 0)
            })
        
        df_pairs = pd.DataFrame(pairs_list)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é outputs
        Path("outputs").mkdir(exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        output_path = "outputs/preselected_pairs.csv"
        df_pairs.to_csv(output_path, index=False)
        
        print(f"üíæ –û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø–∞—Ä:")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø–∞—Ä: {len(df_pairs)}")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π half-life: {df_pairs['half_life'].mean():.2f} –¥–Ω–µ–π")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π p-value: {df_pairs['pvalue'].mean():.4f}")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π Hurst: {df_pairs['hurst'].mean():.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        norm_params_path = "outputs/training_normalization_params.csv"
        if training_normalization_params:
            pd.Series(training_normalization_params).to_csv(norm_params_path)
            print(f"üíæ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {norm_params_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        full_data_path = "outputs/full_step_data.csv"
        step_df.to_csv(full_data_path)
        print(f"üíæ –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —à–∞–≥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {full_data_path}")

        print("\n‚úÖ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –ø–∞—Ä –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print("üìä –¢–û–ß–ù–û –ü–û–í–¢–û–†–ï–ù–ê –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–≤–æ–≥–æ walk-forward —à–∞–≥–∞")
        print("üöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –±—ã—Å—Ç—Ä—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é:")
        print("   poetry run python scripts/fast_optimize.py")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–±–æ—Ä–µ –ø–∞—Ä: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –ø–∞—Ä –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    parser.add_argument("--relaxed", action="store_true",
                       help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å relaxed –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –æ—Å–ª–∞–±–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")
    args = parser.parse_args()

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ñ—É–Ω–∫—Ü–∏–∏
    if args.relaxed:
        os.environ["USE_RELAXED_CONFIG"] = "true"

    preselect_and_save_pairs()
