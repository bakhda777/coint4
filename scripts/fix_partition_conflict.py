#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –ø–∞—Ä—Ç–∏—Ü–∏–π.
–£–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ª–±–µ—Ü 'symbol' –∏–∑ parquet —Ñ–∞–π–ª–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø–∞–ø–æ–∫.
"""

import pandas as pd
from pathlib import Path
from typing import List
import logging
from tqdm import tqdm

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def find_all_parquet_files(data_dir: Path) -> List[Path]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ parquet —Ñ–∞–π–ª—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö."""
    return list(data_dir.glob("**/data.parquet"))


def fix_parquet_file(file_path: Path) -> bool:
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω parquet —Ñ–∞–π–ª - —É–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ª–±–µ—Ü symbol.
    
    Returns:
        True –µ—Å–ª–∏ —Ñ–∞–π–ª –±—ã–ª –∏–∑–º–µ–Ω–µ–Ω, False –µ—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = pd.read_parquet(file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å—Ç–æ–ª–±–µ—Ü symbol
        if 'symbol' not in df.columns:
            return False  # –§–∞–π–ª —É–∂–µ –≤ –ø–æ—Ä—è–¥–∫–µ
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü symbol
        df_fixed = df.drop(columns=['symbol'])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        df_fixed.to_parquet(file_path, index=False)
        
        logger.debug(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω —Ñ–∞–π–ª: {file_path}")
        return True
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
        return False


def fix_data_clean_partitions(data_dir: Path = Path("data_clean")):
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ parquet —Ñ–∞–π–ª—ã –≤ data_clean, —É–¥–∞–ª—è—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–π —Å—Ç–æ–ª–±–µ—Ü symbol.
    """
    if not data_dir.exists():
        logger.error(f"–ü–∞–ø–∫–∞ {data_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    logger.info(f"–ü–æ–∏—Å–∫ parquet —Ñ–∞–π–ª–æ–≤ –≤ {data_dir}")
    parquet_files = find_all_parquet_files(data_dir)
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(parquet_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
    
    if not parquet_files:
        logger.warning("Parquet —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    files_fixed = 0
    files_skipped = 0
    errors = 0
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
    for file_path in tqdm(parquet_files, desc="–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤"):
        try:
            was_fixed = fix_parquet_file(file_path)
            if was_fixed:
                files_fixed += 1
            else:
                files_skipped += 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
            errors += 1
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    logger.info("=" * 50)
    logger.info("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
    logger.info(f"–§–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {len(parquet_files)}")
    logger.info(f"–§–∞–π–ª–æ–≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {files_fixed}")
    logger.info(f"–§–∞–π–ª–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –≤ –ø–æ—Ä—è–¥–∫–µ): {files_skipped}")
    logger.info(f"–û—à–∏–±–æ–∫: {errors}")
    logger.info("=" * 50)
    
    if files_fixed > 0:
        logger.info("‚úÖ –ö–æ–Ω—Ñ–ª–∏–∫—Ç –ø–∞—Ä—Ç–∏—Ü–∏–π –∏—Å–ø—Ä–∞–≤–ª–µ–Ω!")
        logger.info("üéâ –¢–µ–ø–µ—Ä—å Dask/PyArrow –±—É–¥–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏")
    else:
        logger.info("‚ÑπÔ∏è –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")


def test_fixed_data():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
    try:
        from src.coint2.core.data_loader import DataHandler
        from coint2.utils.config import load_config
        import pandas as pd
        
        logger.info("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        config = load_config(Path("configs/main.yaml"))
        handler = DataHandler(config)
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        start_date = pd.Timestamp('2024-01-01')  
        end_date = pd.Timestamp('2024-01-02')
        
        df = handler.preload_all_data(start_date, end_date)
        if not df.empty:
            logger.info(f"‚úÖ –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω! –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
            logger.info(f"–°—Ç–æ–ª–±—Ü—ã: {list(df.columns)[:10]}...")
        else:
            logger.warning("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –ø–∞—Ä—Ç–∏—Ü–∏–π –≤ data_clean")
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã
    fix_data_clean_partitions()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    test_fixed_data()
    
    logger.info("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    main() 